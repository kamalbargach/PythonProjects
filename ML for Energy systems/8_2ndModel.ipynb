{"cells":[{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1697137105359,"execution_millis":1614,"deepnote_to_be_reexecuted":false,"cell_id":"4f8c8801ae614e93a3bda7c589c303f6","deepnote_cell_type":"code"},"source":"import numpy as np \nimport pandas as pd \nimport gurobipy as gp\nfrom gurobipy import GRB\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom datetime import datetime\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nfrom sklearn.model_selection import GridSearchCV, TimeSeriesSplit, cross_val_score\n\nimport matplotlib \nfrom matplotlib import pyplot as plt \n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\n\nfrom sklearn import tree","block_group":"7f572db2ad0a400c845aa18ca044eca6","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1697137106956,"execution_millis":42,"deepnote_to_be_reexecuted":false,"cell_id":"c03b3eb60e334e9eb8f7ac5ca0a5d97f","deepnote_cell_type":"code"},"source":"def load_data():\n    df_wind = pd.read_csv(\"Processed_data.csv\",index_col= 0)\n    prices_df = pd.read_csv(\"Prices_processed.csv\",index_col =0).round(1)\n\n    #train, test_prices = train_test_split(prices, test_size=0.25)\n    \n    Wind_data = df_wind.Actual\n\n    #For calculating whole, \n    prices_train, prices_test, wind_train, wind_test = train_test_split(prices_df, Wind_data, test_size=0.25, shuffle = False)\n\n    P_DA_vals,obj_val,p_E_up_list,p_E_down_list = Optimization_wind(Wind_data,prices_df)\n\n    P_DA_vals = pd.Series(P_DA_vals)\n\n    p_E_up_arr = np.array(p_E_up_list)\n    p_E_down_arr = np.array(p_E_down_list)\n\n\n    #obj_vals_hour_arr = np.array(list(obj_vals_hour.items()))[:,1].flatten()\n    vals_df = pd.concat([prices_df,df_wind[\"mean_wind_speed\"]],axis=1).drop(columns=\"HourUTC\")\n    vals_df = prices_df.drop(columns=\"HourUTC\")\n    \n    #x_train_pda, x_test_pda, y_train_pda, y_test_pda  = train_test_split(vals_df, P_DA_vals, test_size=0.25, shuffle = False)\n    #scaler = MinMaxScaler()\n    #x_train_pda_scaled = pd.DataFrame(scaler.fit_transform(x_train_pda.values), columns=vals_df.columns, index=x_train_pda.index)\n    #x_test_pda_scaled = pd.DataFrame(scaler.transform(x_test_pda.values), columns=vals_df.columns, index=x_test_pda.index)\n\n    scaler = MinMaxScaler()\n    vals_df_scaled = pd.DataFrame(scaler.fit_transform(vals_df.values), columns=vals_df.columns, index=vals_df.index)\n\n    x_train_pda_scaled , x_test_pda_scaled, y_train_pda, y_test_pda  = train_test_split(vals_df_scaled, P_DA_vals, test_size=0.25, shuffle = False)\n    \n    return x_train_pda_scaled , x_test_pda_scaled, y_train_pda, y_test_pda ,prices_train, prices_test, wind_train, wind_test ,prices_df\n","block_group":"50c88e1de915448b940c5c6d1780570f","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1697137106963,"execution_millis":59,"deepnote_to_be_reexecuted":false,"cell_id":"f6818d3777ac404faf9be17797c61745","deepnote_cell_type":"code"},"source":"def Optimization_wind(p_real,prices):\n    p_real = p_real.to_numpy()\n    Time = len(p_real)\n    T = range(Time)\n\n    DA_prices = prices[\"SpotPriceEUR\"].to_numpy()+0.0001\n    Up_prices = prices[\"Up-regulating_price\"].to_numpy()\n    Down_prices = prices[\"Down-regulating_price\"].to_numpy()\n    Capacity = 1 \n\n    psi_up= Up_prices -DA_prices\n    psi_down = DA_prices- Down_prices\n\n    model_opt = gp.Model(\"Step1_A\")\n    p_DA_A = model_opt.addVars(Time,lb=0)\n    p_delt = model_opt.addVars(Time,lb=-gp.GRB.INFINITY,ub=gp.GRB.INFINITY)\n\n    p_E_up = model_opt.addVars(Time,lb =-1,ub=0)\n    p_E_down = model_opt.addVars(Time,lb =0,ub=1)\n\n    model_opt.setObjective(\n    gp.quicksum(p_DA_A[t]*DA_prices[t] \n            + (Up_prices[t] *  p_E_up[t] + Down_prices[t] *  p_E_down[t]) for t in T )\n            ,gp.GRB.MAXIMIZE)\n\n    \n    model_opt.addConstrs(\n    (p_DA_A[t] <= Capacity\n    for t in T\n    )\n    )\n\n    model_opt.addConstrs(\n    (\n    p_delt[t] == p_real[t]-p_DA_A[t]\n    for t in T\n    )\n    )\n\n    model_opt.addConstrs(\n    (\n    p_delt[t] == p_E_up[t] + p_E_down[t]\n    for t in T\n    )\n    )\n    \n\n    model_opt.setParam('OutputFlag', False )\n    model_opt.optimize()\n    if model_opt.status == GRB.OPTIMAL:\n        obj_val =  model_opt.objVal \n        print(\"Revenue Optimization =\", \"{:.2f}\".format(model_opt.objVal))\n        #print(\"Offering Strategy =\", [\"{:.2f}\".format(p_DA_A[t].x) for t in T])\n        #print(\"Imbalance Power =\", [\"{:.2f}\".format(p_delt[t].x) for t in T])\n        #print(\"Real Power  =\", [\"{:.2f}\".format(p_real[t]) for t in T])\n        P_DA = [p_DA_A[t].x for t in T]\n        obj_vals_hour ={t: p_DA_A[t].x*DA_prices[t] - (Up_prices[t] *  p_E_up[t].x + Down_prices[t] *  p_E_down[t].x) for t in T }\n\n        p_E_up_list =[p_E_up[t].x for t in T]\n        p_E_down_list = [p_E_down[t].x for t in T]\n\n\n    else:\n        print(\"Optimization was not successful\")\n\n    return P_DA,obj_val,p_E_up_list,p_E_down_list","block_group":"bba8e71cba5546b89a00b934827713ce","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1697137106978,"execution_millis":53,"deepnote_to_be_reexecuted":false,"cell_id":"61914fce9b914bd6abe91cf72a40c1cc","deepnote_cell_type":"code"},"source":"def Optimization_PDA(Day_ahead,p_real,prices):\n    p_real = p_real.to_numpy()\n\n    Time = len(Day_ahead)\n    T = range(Time)\n\n\n    DA_prices = prices[\"SpotPriceEUR\"].to_numpy()\n    Up_prices = prices[\"Up-regulating_price\"].to_numpy()\n    Down_prices = prices[\"Down-regulating_price\"].to_numpy()\n\n    Capacity = 1 \n\n    psi_up= Up_prices -DA_prices\n    psi_down = DA_prices- Down_prices\n\n    Model_2_PDA = gp.Model(\"Model_2_PDA\")\n    p_DA_A = Model_2_PDA.addVars(Time,lb=0)\n    p_delt = Model_2_PDA.addVars(Time,lb=-gp.GRB.INFINITY,ub=gp.GRB.INFINITY)\n\n    p_E_up = Model_2_PDA.addVars(Time,lb =-1,ub=0)\n    p_E_down = Model_2_PDA.addVars(Time,lb =0,ub=1)\n\n    Model_2_PDA.setObjective(\n    gp.quicksum(Day_ahead[t]*DA_prices[t] \n            + (Up_prices[t] *  p_E_up[t] + Down_prices[t] *  p_E_down[t]) for t in T )\n            ,gp.GRB.MAXIMIZE)\n\n    Model_2_PDA.addConstrs(\n    (\n    p_delt[t] == p_real[t]-Day_ahead[t]\n    for t in T\n    )\n    )\n    Model_2_PDA.addConstrs(\n    (\n    p_delt[t] == p_E_up[t] + p_E_down[t]\n    for t in T\n    )\n    )\n    Model_2_PDA.setParam('OutputFlag', False )\n    Model_2_PDA.optimize()\n    if Model_2_PDA.status == GRB.OPTIMAL:\n        obj_val =  Model_2_PDA.objVal \n        print(\"Revenue opt with fixed wind   =\", \"{:.2f}\".format(Model_2_PDA.objVal))\n       # print(\"Offering Strategy =\", [\"{:.2f}\".format(Day_ahead[t]) for t in T])\n       # print(\"Imbalance Power =\", [\"{:.2f}\".format(p_delt[t].x) for t in T])\n       # print(\"Upbalance =\", [\"{:.2f}\".format(p_E_up[t].x) for t in T])\n       # print(\"Downbalance =\", [\"{:.2f}\".format(p_E_down[t].x) for t in T])\n       # print(\"Real Power  =\", [\"{:.2f}\".format(p_real[t]) for t in T])\n        P_delt = [p_delt[t].x for t in T]\n        obj_vals_hour ={t: Day_ahead[t]*DA_prices[t] - (Up_prices[t] *  p_E_up[t].x + Down_prices[t] *  p_E_down[t].x) for t in T }\n\n\n    else:\n        print(\"Optimization was not successful\")\n\n    return obj_val, P_delt","block_group":"a469621317554664841739142d6505c7","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1697137106979,"execution_millis":53,"deepnote_to_be_reexecuted":false,"cell_id":"0618857b52a24087ac73e3e1f2ea9cbb","deepnote_cell_type":"code"},"source":"def rfr_regression_PDA(x_train_pda_scaled , x_test_pda_scaled, y_train_pda, y_test_pda):\n    \n    rfr = RandomForestRegressor()\n    param_grid = {\n        'max_depth': [3,5,8,10],\n        'criterion' :['squared_error'],\n        'n_estimators': [10,20,40,]\n    }\n    \n    rfrCV  = GridSearchCV(estimator = rfr, cv=TimeSeriesSplit(n_splits=5),param_grid = param_grid, return_train_score = True)\n    rfrCV.fit(x_train_pda_scaled, y_train_pda)\n    best_rfr = rfrCV.best_estimator_\n    #rfr.fit(X_train, y_train)\n    \n    #Use the trained regression model to make predictions on the test data.\n    y_pred_PDA_rfr = best_rfr.predict(x_test_pda_scaled)\n    \n    y_pred_PDA_rfr[y_pred_PDA_rfr <0] =0\n    \n    #check error \n    print('MSE:',mean_squared_error(y_test_pda,y_pred_PDA_rfr))\n    print('R^2:', r2_score(y_test_pda, y_pred_PDA_rfr, force_finite=False))\n    print('Score:',best_rfr.score(x_train_pda_scaled, y_train_pda))\n    plt.figure(figsize=(10, 6))\n    plt.scatter(y_test_pda,y_pred_PDA_rfr, c='b', label='Fitted Data',alpha=0.4)\n    plt.plot([min(y_test_pda), max(y_test_pda)], [min(y_test_pda), max(y_test_pda)], 'k--', lw=2, label='Ideal Fit')\n    plt.xlabel('True Values')\n    plt.ylabel('Predictions')\n    plt.title('True vs. Predicted Values')\n    plt.legend()\n    plt.show()\n    \n    \n    plt.figure(figsize=(12, 5))\n    plt.scatter(x_test_pda_scaled.index,y_test_pda, c='b', label='True Data',alpha=0.3)\n    plt.scatter(x_test_pda_scaled.index,y_pred_PDA_rfr, c='g', label='Fitted Data',alpha=0.25)\n    plt.xlabel('True Values')\n    plt.ylabel('Predictions')\n    plt.title('True vs. Predicted Values')\n    plt.legend()\n    plt.show()\n    \n    return y_pred_PDA_rfr\n","block_group":"f864bb6438684512b46eb84378fa8672","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1697137106995,"execution_millis":45,"deepnote_to_be_reexecuted":false,"cell_id":"6b9f496a71ee45259ad6e944edadf672","deepnote_cell_type":"code"},"source":"def reg_L1(x_train_pda_scaled , x_test_pda_scaled, y_train_pda, y_test_pda):\n    \n    # Define the Lasso Regression model\n    lasso_model = Lasso()\n    \n    # Define a range of alpha values to test\n    alphas = np.logspace(-6, 6, 13) \n    \n    #Define the 5 fold time-series cross validation\n    \n    param_grid = { \"fit_intercept\" :[True,False],  \"alpha\": alphas}\n    \n    lassoCV  = GridSearchCV(estimator = lasso_model, cv=TimeSeriesSplit(n_splits=5),param_grid = param_grid, return_train_score = True)\n    lassoCV.fit(x_train_pda_scaled, y_train_pda)\n    best_lassoCV = lassoCV.best_estimator_\n    \n  \n    y_pred_cv = best_lassoCV.predict(x_test_pda_scaled)\n    print('MSE:',mean_squared_error(y_test_pda,y_pred_cv))\n    print('R^2:', r2_score(y_test_pda, y_pred_cv, force_finite=False))\n    print('Score:',best_lassoCV.score(x_train_pda_scaled, y_train_pda))\n    \n    \n    \n    \n    plt.figure(figsize=(10, 6))\n    plt.scatter(y_test_pda,y_pred_cv, c='b', label='Fitted Data')\n    plt.plot([min(y_test_pda), max(y_test_pda)], [min(y_test_pda), max(y_test_pda)], 'k--', lw=2, label='Ideal Fit')\n    plt.xlabel('True Values')\n    plt.ylabel('Predictions')\n    plt.title('True vs. Predicted Values')\n    plt.legend()\n    plt.show()\n    \n    plt.figure(figsize=(15, 5))\n    plt.scatter(np.arange(0,len(y_test_pda)),y_test_pda, c='b', label='True Data',alpha=0.5)\n    plt.scatter(np.arange(0,len(y_test_pda)),y_pred_cv, c='g', label='Fitted Data',alpha=0.4)\n    plt.xlabel('True Values')\n    plt.ylabel('Predictions')\n    plt.title('True vs. Predicted Values')\n    plt.legend()\n    plt.show()\n    \n    return y_pred_cv","block_group":"01690100d5be435a9e7d988560750e77","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1697137107004,"execution_millis":59,"deepnote_to_be_reexecuted":false,"cell_id":"4cbde7f718c24b738d6ef2c442b57b78","deepnote_cell_type":"code"},"source":"def reg_L2(x_train_pda_scaled , x_test_pda_scaled, y_train_pda, y_test_pda):\n    \n    \n    # Define the Lasso Regression model\n    ridge_model = Ridge()\n    \n    # Define a range of alpha values to test\n    alphas = np.logspace(-6, 6, 13) \n    \n    #Define the 5 fold time-series cross validation\n    \n    param_grid = { \"fit_intercept\" :[True,False],  \"alpha\": alphas}\n    \n    ridgeCV  = GridSearchCV(estimator = ridge_model, cv=TimeSeriesSplit(n_splits=5),param_grid = param_grid, return_train_score = True)\n    ridgeCV.fit(x_train_pda_scaled, y_train_pda)\n    best_ridgeCV = ridgeCV.best_estimator_\n  \n    y_pred_cv = best_ridgeCV.predict(x_test_pda_scaled)\n\n    print('MSE:',mean_squared_error(y_test_pda,y_pred_cv))\n    print('R^2:', r2_score(y_test_pda, y_pred_cv, force_finite=False))\n    print('Score:',best_ridgeCV.score(x_train_pda_scaled, y_train_pda))\n    \n    \n    \n    \n    plt.figure(figsize=(10, 6))\n    plt.scatter(y_test_pda,y_pred_cv, c='b', label='Fitted Data')\n    plt.plot([min(y_test_pda), max(y_test_pda)], [min(y_test_pda), max(y_test_pda)], 'k--', lw=2, label='Ideal Fit')\n    plt.xlabel('True Values')\n    plt.ylabel('Predictions')\n    plt.title('True vs. Predicted Values')\n    plt.legend()\n    plt.show()\n    \n    plt.figure(figsize=(15, 5))\n    plt.scatter(np.arange(0,len(y_test_pda)),y_test_pda, c='b', label='True Data',alpha=0.5)\n    plt.scatter(np.arange(0,len(y_test_pda)),y_pred_cv, c='g', label='Fitted Data',alpha=0.4)\n    plt.xlabel('True Values')\n    plt.ylabel('Predictions')\n    plt.title('True vs. Predicted Values')\n    plt.legend()\n    plt.show()\n\n    return y_pred_cv","block_group":"cde04da66d384633bbd96385b842c464","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"08c5381d65314a80a3b07514c7ac5128","deepnote_cell_type":"code"},"source":"def clustering_prices(x_train_pda_scaled , x_test_pda_scaled, y_train_pda, y_test_pda ,prices):\n    \n    \"\"\"\n    \n    We manually cluster the prices based on price, and then turn those clustered\n    values into their own data set, that we can then use regerssion on\n    \n    \"\"\"\n    \n    \n    Time = len(prices)\n    T = range(Time)\n    \n    DA_prices = prices[\"SpotPriceEUR\"].to_numpy()\n    Up_prices = prices[\"Up-regulating_price\"].to_numpy()\n    Down_prices = prices[\"Down-regulating_price\"].to_numpy()\n    \n    p_DA_clust = np.empty(Time)\n    \n \n    for t in T:\n        if DA_prices[t] < Down_prices[t] :\n            p_DA_clust[t] = 1\n        elif DA_prices[t] >= Up_prices[t] :\n            p_DA_clust[t] = 2\n        else:\n            p_DA_clust[t] = 0\n    p_DA_clust = pd.Series(p_DA_clust)\n    \n    pDA_train_clust,pDA_test_clust,= train_test_split(p_DA_clust)\n    \n    u_labels_train = np.unique(pDA_train_clust).astype(int)\n    u_labels_test = np.unique(pDA_test_clust).astype(int)\n\n    # Create a list of indices at which to split the array\n    split_indices_train = []\n    split_indices_test = []\n    clusted_dfs_train = []\n    clustered_y_train = []\n    clusted_dfs_test = []\n    clustered_y_test = []\n    \n    fig, axes = plt.subplots(3, sharex=True)\n    #Cluster of time series \n    for (i,ax) in enumerate(axes.flatten()):\n        ax.set_title(\"Cluster \" + str(i+1))\n        ax.set_ylabel(\"Day Ahead Bid\")\n        ax.set_xlabel(\"Time\")\n        ax.plot(x_test_pda_scaled.index, y_test_pda, 'r-',label = \"orig\",alpha = 0.4,linewidth = 1.5)\n        ax.plot(x_test_pda_scaled[p_DA_clust == i].index, y_test_pda[p_DA_clust == i], 'g-',label = \"Cluster\",alpha =0.6, linewidth = 3)\n    handles, labels = ax.get_legend_handles_labels()\n    fig.legend(handles, labels, loc='lower center')\n    fig.suptitle('Wind production seperated into clusters vs time :Test Set ', fontsize=16)\n    fig.tight_layout()\n    plt.show()\n     \n     \n     #save each train cluster into their own dataframe  and to list \n    for i in range(len(u_labels_train)):\n        split_indices_train.append(np.where(pDA_train_clust == i)[0])\n        clusted_dfs_train.append( x_train_pda_scaled.iloc[split_indices_train[i]].reset_index(drop=True))\n        clustered_y_train.append(y_train_pda.iloc[split_indices_train[i]].reset_index(drop=True))\n        \n        \n     #save each test cluster into their own dataframe  and to list \n    for i in range(len(u_labels_test)):\n       \n        split_indices_test.append(np.where(pDA_test_clust == u_labels_test[i])[0])\n        clusted_dfs_test.append(x_test_pda_scaled.iloc[split_indices_test[i]])\n        clustered_y_test.append(y_test_pda.iloc[split_indices_test[i]])\n    \n    \n    #Local regression \n    \n    \n    return u_labels_train, u_labels_test, clusted_dfs_train, clustered_y_train, clusted_dfs_test, clustered_y_test","block_group":"e556db7c366743c4a2d969dc5c598bc6","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"877bf8ea542541ab9068d06dcf7180e2","deepnote_cell_type":"code"},"source":"def clusted_rfr(label_train,u_labels_test,clusted_dfs_train,clustered_y_train,clusted_dfs_test,clustered_y_test): \n    \n    \"\"\"\n    Input training data seperated into per cluster\n    A Random Forest regression is trained on the clusted data \n    \n    When all clusters have been trained and predicted with its best estimator, \n    all the predictions are recombined into one set with their orignial index so time is maintained\n    \n    This model has an issue and computes the value wrong somewhere\n    \n    return: recombined test data, best MSE of all models, best r-score of all models \n    \"\"\"\n    \n    #Estimator paramters to be checked for best \n    rfr = RandomForestRegressor()\n    param_grid = {\n        'max_depth': [3,5,8,10],\n        'criterion' :['squared_error'],\n        'n_estimators': [10,20,40,]\n    } \n    \n    \n    y_pred_list = []\n    y_pred_df = []\n    \n    r_scores = np.empty(len(u_labels_test))\n    mse_scores = np.empty(len(u_labels_test))\n    fig, axes = plt.subplots(3, sharex=True)\n    #Each cluster is trained individually and best is kept \n    for (k,ax) in enumerate(axes.flatten()):\n\n        x_train = clusted_dfs_train[k]\n        y_train = clustered_y_train[k]\n        \n        x_test =clusted_dfs_test[k]\n        y_test = clustered_y_test[k]\n        \n        \n        rfrCV  = GridSearchCV(estimator = rfr, cv=TimeSeriesSplit(n_splits=5),param_grid = param_grid, return_train_score = True)\n        rfrCV.fit(x_train, y_train)\n        best_rfr = rfrCV.best_estimator_\n        \n        y_pred_sk = best_rfr.predict(x_test)\n        \n        #Save to list \n        y_pred_list.append(y_pred_sk)\n        y_pred_df.append(pd.DataFrame(y_pred_sk,index=y_test.index))\n        \n        print('MSE:',mean_squared_error(y_test,y_pred_sk))\n        print('R^2:', r2_score(y_test, y_pred_sk, force_finite=False))\n        \n        r_scores[k] = r2_score(y_test, y_pred_sk, force_finite=False)\n        mse_scores[k] = mean_squared_error(y_test,y_pred_sk)\n        \n        \n        ax.set_title(\"Cluster \" + str(k+1))\n        ax.set_ylabel(\"Wind Power\")\n        ax.set_xlabel(\"Time\")\n        ax.plot(x_test.index, y_test, 'r-',label = \"Orig\",alpha=0.7)\n        ax.plot(x_test.index, y_pred_sk, 'g-',label = \"Cluster\",alpha=0.6)\n   \n    \n    handles, labels = ax.get_legend_handles_labels()\n    fig.legend(handles, labels, loc='lower center')\n    fig.suptitle('Random forrest on Wind Forecast: Test Set', fontsize=16)\n    fig.tight_layout()\n    plt.show()\n    \n    #all clusters recombined , index maintained \n    Clust_rfr_combined = pd.concat(y_pred_df).squeeze()\n    \n    return Clust_rfr_combined,r_scores,mse_scores","block_group":"a30963c4f63546898cd2ec10449afaf2","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"a651fde9e65141bc9988e866a943fbec","deepnote_cell_type":"code"},"source":"def decision_tree(x_train_pda_scaled , x_test_pda_scaled, y_train_pda, y_test_pda):\n    \n    clf = tree.DecisionTreeRegressor()\n    \n    params = { 'max_depth' : [1,2,3], \n        }\n    \n    grid_clf = GridSearchCV(clf, param_grid = params, cv=TimeSeriesSplit(n_splits=5))\n    grid_clf.fit(x_train_pda_scaled,y_train_pda)\n    \n    best_clf = grid_clf.best_estimator_\n    \n  \n    y_pred_clf = best_clf.predict(x_test_pda_scaled)\n    print('MSE:',mean_squared_error(y_test_pda,y_pred_clf))\n    print('R^2:', r2_score(y_test_pda, y_pred_clf, force_finite=False))\n    print('Score:',best_clf.score(x_train_pda_scaled, y_train_pda))\n    \n    plt.figure(figsize=(10, 6))\n    plt.scatter(y_test_pda,y_pred_clf, c='b', label='Fitted Data')\n    plt.plot([min(y_test_pda), max(y_test_pda)], [min(y_test_pda), max(y_test_pda)], 'k--', lw=2, label='Ideal Fit')\n    plt.xlabel('True Values')\n    plt.ylabel('Predictions')\n    plt.title('True vs. Predicted Values')\n    plt.legend()\n    plt.show()\n    \n    plt.figure(figsize=(15, 5))\n    plt.scatter(np.arange(0,len(y_test_pda)),y_test_pda, c='b', label='True Data',alpha=0.5)\n    plt.scatter(np.arange(0,len(y_test_pda)),y_pred_clf, c='g', label='Fitted Data',alpha=0.4)\n    plt.xlabel('True Values')\n    plt.ylabel('Predictions')\n    plt.title('True vs. Predicted Values')\n    plt.legend()\n    plt.show()\n    \n    \n    return y_pred_clf","block_group":"c72514fab2fe42ff96007387f19d41a0","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"9ea23196e4a94744a780bec79c41e0f8","deepnote_cell_type":"code"},"source":"def balancing_revenue(P_DA_bid, p_real, prices):\n    \n    \"\"\"\n    \n    Input: \n    Bids made for Day ahead market\n    The actual wind production \n    The prices for test set\n    \n    We calculate the realization of our day ahead bid in the market\n    \n    Output: \n        \n    Revenue: Our actual money gained\n    \n    Up and down regulation made by our Day ahead bid\n    \n    \"\"\"\n    \n    Time = len(P_DA_bid)\n    T = range(Time)\n    p_real = p_real.to_numpy()\n    \n    if isinstance(P_DA_bid,pd.core.series.Series):\n        P_DA_bid = P_DA_bid.to_numpy()\n    \n\n    DA_prices = prices[\"SpotPriceEUR\"].to_numpy()\n    Up_prices = prices[\"Up-regulating_price\"].to_numpy()\n    Down_prices = prices[\"Down-regulating_price\"].to_numpy()\n    \n    p_up = np.empty(Time)\n    p_down = np.empty(Time)\n \n    for t in T:\n        if p_real[t] <= P_DA_bid[t] :\n            p_up[t] = p_real[t] -P_DA_bid[t]\n        else:\n            p_up[t] = 0\n        if p_real[t] > P_DA_bid[t] :\n            p_down[t] = p_real[t] - P_DA_bid[t]\n        else:\n            p_down[t] = 0\n    Revenue = np.dot(P_DA_bid,DA_prices) + np.dot(p_up,Up_prices) + np.dot(p_down,Down_prices)\n    \n    return Revenue, p_up,p_down\n","block_group":"56b0144d01384769ab5a8ac11af753d0","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"c438e98678aa4afd9760cc1855123386","deepnote_cell_type":"text-cell-h2"},"source":"## Main for 2nd model, uncomment to run ","block_group":"0ddcc3fa0a164f1d819e8db7963f0b4e"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1697137107008,"execution_millis":2778,"deepnote_to_be_reexecuted":false,"cell_id":"04f7703fdfe0410f91a96c744c48f5c8","deepnote_cell_type":"code"},"source":"#Get data for use\nx_train_pda_scaled , x_test_pda_scaled, y_train_pda, y_test_pda ,prices_train ,\\\nprices_test, wind_train, wind_test, prices = load_data()\n\n#y_pred_tree = decision_tree(x_train_pda_scaled , x_test_pda_scaled, y_train_pda, y_test_pda)\n\n#Normal regression\ny_pred_PDA_reg = regression_PDA(x_train_pda_scaled , x_test_pda_scaled, y_train_pda, y_test_pda)\n\n#lasso regression PDA \ny_pred_PDA_L1 = reg_L1(x_train_pda_scaled , x_test_pda_scaled, y_train_pda, y_test_pda)\n\n#Ridge regression PDA \ny_pred_PDA_L2 = reg_L2(x_train_pda_scaled , x_test_pda_scaled, y_train_pda, y_test_pda)\n\n#Random forest regressor prediction on Day ahead bidding \ny_pred_PDA_rfr = rfr_regression_PDA(x_train_pda_scaled , x_test_pda_scaled, y_train_pda, y_test_pda)\n\n\n\n#Clustered rfr\nu_labels_train, u_labels_test, clusted_dfs_train, clustered_y_train, clusted_dfs_test, clustered_y_test = clustering_prices(x_train_pda_scaled , x_test_pda_scaled, y_train_pda, y_test_pda ,prices)\nclust_rfr_pred,r_scores,mse_scores = clusted_rfr(u_labels_train, u_labels_test, clusted_dfs_train, clustered_y_train, clusted_dfs_test, clustered_y_test)\n\n\n\n#Fixing values to between [0,1]\ny_pred_PDA_reg_copy = y_pred_PDA_reg\ny_pred_PDA_reg_copy[y_pred_PDA_reg_copy <0] =0\ny_pred_PDA_reg_copy[y_pred_PDA_reg_copy >1] =1\n\ny_pred_PDA_L1_copy = y_pred_PDA_L1\ny_pred_PDA_L1_copy[y_pred_PDA_L1_copy <0] =0\ny_pred_PDA_L1_copy[y_pred_PDA_L1_copy >1] =1\n\n\ny_pred_PDA_L2_copy = y_pred_PDA_L2\ny_pred_PDA_L2_copy[y_pred_PDA_L2_copy <0] =0\ny_pred_PDA_L2_copy[y_pred_PDA_L2_copy >1] =1\n\n\n\n#Revenue calculations for each prediction\n\n#Optimal optimization value , just to verify balancing revenue function\nP_DA_opt,obj_val_opt,p_E_up_list_opt,p_E_down_list_opt= Optimization_wind(wind_test,prices_test)\nRevenue_opt, p_up_opt,p_down_opt = balancing_revenue(y_test_pda, wind_test, prices_test)\n\n\nRevenue_reg, p_up_reg,p_down_reg = balancing_revenue(y_pred_PDA_reg_copy, wind_test, prices_test)\n\nRevenue_L1, p_up_L1,p_down_L1 = balancing_revenue(y_pred_PDA_L1_copy, wind_test, prices_test)\n\n\nRevenue_L2, p_up_L2,p_down_L2 = balancing_revenue(y_pred_PDA_L2_copy, wind_test, prices_test)\n\n\nRevenue_rfr, p_up_rfr,p_down_rfr = balancing_revenue(y_pred_PDA_rfr, wind_test, prices_test)\n\nRevenue_clust_rfr, p_up_clust_rfr,p_down_clust_rfr  =balancing_revenue(clust_rfr_pred,wind_test,prices_test)\n\n\n\n#Plotting \nn_bins = 6\n\n#Histogram plot \nfig, axs = plt.subplots(1, 6, sharey=True, tight_layout=True,figsize=(12, 4))\naxs[0].hist(y_test_pda, bins=n_bins,color='lightblue', ec=\"black\", lw=2)\naxs[0].set(xticks=np.linspace(0,1,n_bins))\naxs[0].set_title(\"Opt Model\")\n\naxs[1].hist(y_pred_PDA_reg, bins=n_bins,color='lightblue', ec=\"black\", lw=2)\naxs[1].set(xticks=np.linspace(0,1,n_bins))\naxs[1].set_title(\"Regression\")\n\naxs[2].hist(y_pred_PDA_L1, bins=n_bins,color='lightblue', ec=\"black\", lw=2)\naxs[2].set(xticks=np.linspace(0,1,n_bins))\naxs[2].set_title(\"L1 Regression\")\n\naxs[3].hist(y_pred_PDA_L2, bins=n_bins,color='lightblue', ec=\"black\", lw=2)\naxs[3].set(xticks=np.linspace(0,1,n_bins))\naxs[3].set_title(\"L2 Regression\")\n\n\naxs[4].hist(y_pred_PDA_rfr, bins=n_bins,color='lightblue', ec=\"black\", lw=2)\naxs[4].set(xticks=np.linspace(0,1,n_bins))\naxs[4].set_title(\"RFR Regression\")\n\naxs[5].hist(clust_rfr_pred, bins=n_bins,color='lightblue', ec=\"black\", lw=2)\naxs[5].set(xticks=np.linspace(0,1,n_bins))\naxs[5].set_title(\"Clustered RFR Regression\")\nfig.suptitle('Distribution of Day Ahead Bids', fontsize=18)\nfig.supylabel(\"Count of Day Ahead bids\",fontsize=14)\nfig.supxlabel(\"Value of Day Ahead bids\",fontsize=14)\n\nplt.show()\n\n#True vs Pred plot \n\n\nfig, axs = plt.subplots(1, 5, sharey=True, tight_layout=True,figsize=(12, 4))\naxs[0].scatter(y_test_pda,y_pred_PDA_reg, c='b', label='Fitted Data',alpha=0.4)\naxs[0].plot([min(y_test_pda), max(y_test_pda)], [min(y_test_pda), max(y_test_pda)], 'k--', lw=2, label='Ideal Fit')\naxs[0].set_title(\"Regression\")\n\naxs[1].scatter(y_test_pda,y_pred_PDA_L1, c='b', label='Fitted Data',alpha=0.4)\naxs[1].plot([min(y_test_pda), max(y_test_pda)], [min(y_test_pda), max(y_test_pda)], 'k--', lw=2, label='Ideal Fit')\naxs[1].set_title(\"L1 Regression\")\n\naxs[2].scatter(y_test_pda,y_pred_PDA_L2, c='b', label='Fitted Data',alpha=0.4)\naxs[2].plot([min(y_test_pda), max(y_test_pda)], [min(y_test_pda), max(y_test_pda)], 'k--', lw=2, label='Ideal Fit')\naxs[2].set_title(\"L2 Regression\")\n\naxs[3].scatter(y_test_pda,y_pred_PDA_rfr, c='b', label='Fitted Data',alpha=0.4)\naxs[3].plot([min(y_test_pda), max(y_test_pda)], [min(y_test_pda), max(y_test_pda)], 'k--', lw=2, label='Ideal Fit')\naxs[3].set_title(\"RFR Regression\")\n\naxs[4].scatter(y_test_pda,clust_rfr_pred, c='b', label='Fitted Data',alpha=0.4)\naxs[4].plot([min(y_test_pda), max(y_test_pda)], [min(y_test_pda), max(y_test_pda)], 'k--', lw=2, label='Ideal Fit')\naxs[4].set_title(\"RFR Regression\")\n\nhandles, labels = axs[3].get_legend_handles_labels()\nfig.legend(handles, labels, loc='upper right')\nfig.supxlabel(\"True Value\", fontsize=14)\nfig.supylabel(\"Predicted Value \",fontsize=14)\nfig.suptitle('Prediction Vs True', fontsize=18)\nplt.show()\n","block_group":"86877b1e5ec54168a3621a6430e3ae9f","execution_count":null,"outputs":[{"name":"stdout","text":"Restricted license - for non-production use only - expires 2024-10-28\n","output_type":"stream"},{"output_type":"error","ename":"GurobiError","evalue":"Model too large for size-limited license; visit https://www.gurobi.com/free-trial for a full license","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mGurobiError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn [8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m x_train_pda_scaled , x_test_pda_scaled, y_train_pda, y_test_pda ,prices_train ,\\\n\u001b[0;32m----> 2\u001b[0m prices_test, wind_train, wind_test \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m#Optimal optimization value \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mP_DA_opt,obj_val_opt,p_E_up_list_opt,p_E_down_list_opt= Optimization_wind(wind_test,prices_test)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03mobj_rfr/obj_val_opt\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m clustering_prices(x_train_pda_scaled , x_test_pda_scaled, y_train_pda, y_test_pda)\n","Cell \u001b[0;32mIn [2], line 16\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#For calculating whole, \u001b[39;00m\n\u001b[1;32m     13\u001b[0m prices_train, prices_test, wind_train, wind_test \u001b[38;5;241m=\u001b[39m train_test_split(prices_df, Wind_data, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 16\u001b[0m P_DA_vals,obj_val,p_E_up_list,p_E_down_list \u001b[38;5;241m=\u001b[39m \u001b[43mOptimization_wind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWind_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprices_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m P_DA_vals \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(P_DA_vals)\n\u001b[1;32m     20\u001b[0m p_E_up_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(p_E_up_list)\n","Cell \u001b[0;32mIn [3], line 49\u001b[0m, in \u001b[0;36mOptimization_wind\u001b[0;34m(Windspeed, prices)\u001b[0m\n\u001b[1;32m     40\u001b[0m model_opt\u001b[38;5;241m.\u001b[39maddConstrs(\n\u001b[1;32m     41\u001b[0m (\n\u001b[1;32m     42\u001b[0m p_delt[t] \u001b[38;5;241m==\u001b[39m p_E_up[t] \u001b[38;5;241m+\u001b[39m p_E_down[t]\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m T\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     48\u001b[0m model_opt\u001b[38;5;241m.\u001b[39msetParam(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutputFlag\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m )\n\u001b[0;32m---> 49\u001b[0m \u001b[43mmodel_opt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_opt\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m GRB\u001b[38;5;241m.\u001b[39mOPTIMAL:\n\u001b[1;32m     51\u001b[0m     obj_val \u001b[38;5;241m=\u001b[39m  model_opt\u001b[38;5;241m.\u001b[39mobjVal \n","File \u001b[0;32msrc/gurobipy/model.pxi:878\u001b[0m, in \u001b[0;36mgurobipy.Model.optimize\u001b[0;34m()\u001b[0m\n","\u001b[0;31mGurobiError\u001b[0m: Model too large for size-limited license; visit https://www.gurobi.com/free-trial for a full license"]}]},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=538942fa-4593-4d1a-b90d-2d23669fe78c' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"1ec3788f93024d9fb0b959d7555f4dc9","deepnote_persisted_session":{"createdAt":"2023-10-12T19:16:19.397Z"},"deepnote_execution_queue":[]}}